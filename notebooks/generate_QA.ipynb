{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fdde1b",
   "metadata": {},
   "source": [
    "# QA dataset generation\n",
    "\n",
    "This notebook contains code to generate a question-answering dataset using a given text corpus. The dataset will consist of questions derived from the text along with their corresponding answers.\n",
    "\n",
    "The dataset will be created using OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16dce5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd48721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Configuration\n",
    "# --------------------------------------------------\n",
    "INPUT_CSV = \"../data/raw/bmw_press_releases.csv\"\n",
    "OUTPUT_CSV = \"../data/QA/article_qa.csv\"\n",
    "OUTPUT_JSON_DIR = \"../data/QA/qa_s/\"\n",
    "TEXT_COLUMN = \"content\"\n",
    "MODEL = \"gpt-4.1-mini\"  # cost-efficient and reliable for structured generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a44a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Load environment variables\n",
    "# --------------------------------------------------\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c79ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Prompt template\n",
    "# --------------------------------------------------\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a dataset generation assistant. \"\n",
    "    \"Given an article, generate exactly one high-quality, \"\n",
    "    \"answerable question and answer based solely on the content.\"\n",
    "    \"The answer should consist of maximum 3 words.\"\n",
    ")\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "Article:\n",
    "\\\"\\\"\\\"\n",
    "{article_text}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Return the output strictly as JSON in the following format:\n",
    "\n",
    "{{\n",
    "    \"question\": \"Your generated question here?\",\n",
    "    \"answer\": \"The corresponding answer here.\"\n",
    "}}\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ccce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Helper function\n",
    "# --------------------------------------------------\n",
    "def generate_questions(article_text: str) -> list[str]:\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": USER_PROMPT_TEMPLATE.format(article_text=article_text),\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    parsed = json.loads(content)\n",
    "\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af9de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(INPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1562cccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing file: ../data/QA/qa_s/qa_article_iconic-bmw-art-cars-by-andy-warhol-and-julie-mehretu-are-coming-to-north-america-bmw-art-car-world-tour-stops-at-pebble-beach-concours-d%E2%80%99elegance-and-the-bridge.json\n",
      "Skipping existing file: ../data/QA/qa_s/qa_article_bmw-group-foerdert-junge-vordenker.json\n",
      "Skipping existing file: ../data/QA/qa_s/qa_article_turning-old-into-new:-recycling-as-next-step-towards-greater-circular-economy-for-bmw-group-3d-printing.json\n",
      "Skipping existing file: ../data/QA/qa_s/qa_article_bmw-group-plant-regensburg-pilots-thermal-oil-system-for-heat-generation-in-paint-shop.json\n",
      "Skipping existing file: ../data/QA/qa_s/qa_article_nelson-piquet-tribute:-bmw-group-classic-brought-legendary-bmw-race-cars-to-the-%E2%80%9Ccircuito-estoril%E2%80%9D-in-honour-of-the-three-time-formula-1-world-champion.json\n",
      "Skipping existing file: ../data/QA/qa_s/qa_article_indianapolis-8-hour:-kelvin-van-der-linde-wins-the-igtc-drivers%E2%80%99-title-%E2%80%93-bmw-m-motorsport-secures-manufacturers%E2%80%99-championship.json\n",
      "Skipping existing file: ../data/QA/qa_s/qa_article_bmw-celebrates-25-years-of-the-preis-der-nationalgalerie-to-mark-this-milestone-john-baldessari-s-bmw-art-car-is-presented-on-the-terrace-of-the-neue-nationalgalerie.json\n",
      "Skipping existing file: ../data/QA/qa_s/qa_article_%E2%80%9Cdunks-for-tomorrow%E2%80%9D-creating-real-opportunities-in-life:-bmw-supports-dein-muenchen-s-education-programme-with-%E2%82%AC125-000.json\n",
      "Skipping existing file: ../data/QA/qa_s/qa_article_satellite-details-bmw-group-keynote-world-premiere-of-the-new-bmw-ix3.json\n",
      "Skipping existing file: ../data/QA/qa_s/qa_article_bmw-m-racing-academy:-class-of-2026-starts-with-three-customer-racing-drivers-from-three-continents.json\n",
      "Saved QA pairs to ../data/QA/qa_s/qa_article_mini-jcw-x-deus-ex-machina:-two-worlds-two-cars-singular-enthusiasm.json\n",
      "Saved QA pairs to ../data/QA/qa_s/qa_article_maurizio-cattelan-receives-the-preis-der-nationalgalerie-2026-bmw-supports-the-award-since-2006-underlining-its-vision-that-artistic-thinking-inspires-innovation-and-social-change.json\n",
      "Saved QA pairs to ../data/QA/qa_s/qa_article_world-premiere-bmw-ix3.json\n",
      "Saved QA pairs to ../data/QA/qa_s/qa_article_bmw-group-brazil-and-unicef-join-forces-to-transform-the-future-of-vulnerable-youth.json\n",
      "Saved QA pairs to ../data/QA/qa_s/qa_article_bmw-and-jung-von-matt-present-international-launch-campaign-for-the-bmw-ix3.json\n"
     ]
    }
   ],
   "source": [
    "# For each article, generate questions and store them in json format first - skip if exists\n",
    "os.makedirs(OUTPUT_JSON_DIR, exist_ok=True)\n",
    "no_articles = 0\n",
    "for idx, row in df.iterrows():\n",
    "    article_url = row['url']\n",
    "    article_name = article_url.split(\"/\")[-1]\n",
    "    \n",
    "    filename = os.path.join(OUTPUT_JSON_DIR, f\"qa_article_{article_name}.json\")\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Skipping existing file: {filename}\")\n",
    "        continue\n",
    "    article_text = row[TEXT_COLUMN]\n",
    "    qa = {\n",
    "        \"article_title\": row['title'],\n",
    "        \"article_url\": article_url,\n",
    "        \"question\": \"\",\n",
    "        \"answer\": \"\"\n",
    "    }\n",
    "    qa.update(generate_questions(article_text))\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(qa, f, indent=2)\n",
    "    print(f\"Saved QA pairs to {filename}\")\n",
    "    no_articles += 1\n",
    "    if no_articles >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544b46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all generated QA pairs and save to a single CSV\n",
    "qa_data = []\n",
    "for file in os.listdir(OUTPUT_JSON_DIR):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(OUTPUT_JSON_DIR, file), \"r\") as f:\n",
    "            qa_entry = json.load(f)\n",
    "            qa_data.append(qa_entry)\n",
    "qa_df = pd.DataFrame(qa_data)\n",
    "qa_df.to_csv(OUTPUT_CSV, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
